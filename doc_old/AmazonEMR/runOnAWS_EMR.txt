aws emr create-cluster --termination-protected --applications Name=Hadoop --bootstrap-actions '[{"Path":"s3://amidst2/emr_bootstrap_java_8_emr400.sh","Name":"Bootstrap action"}]' --ec2-attributes '{"KeyName":"AmidstToolbox","InstanceProfile":"EMR_EC2_DefaultRole","SubnetId":"subnet-0e205679","EmrManagedSlaveSecurityGroup":"sg-e07dea84","EmrManagedMasterSecurityGroup":"sg-e77dea83"}' --service-role EMR_DefaultRole --enable-debugging --release-label emr-4.3.0 --log-uri 's3n://amidst2/logsForClusters/' --name 'TestCluster4_2onlyAggTrue' --instance-groups '[{"InstanceCount":1,"InstanceGroupType":"MASTER","InstanceType":"m3.xlarge","Name":"MASTER"},{"InstanceCount":2,"InstanceGroupType":"CORE","InstanceType":"m3.xlarge","Name":"CORE"}]' --region us-west-2 


aws emr describe-cluster --cluster-id j-28GP6VSDGF5IA

ssh hadoop@ec2-54-200-118-231.us-west-2.compute.amazonaws.com -i ~/key/AmidstToolbox.pem 

wget http://ftp.download-by.net/apache/flink/flink-0.10.0/flink-0.10.0-bin-hadoop26-scala_2.10.tgz
tar xzf flink-*.tgz
export HADOOP\_CONF\_DIR=/etc/hadoop/conf
#sudo yum update -y

scp -i ~/key/AmidstToolbox.pem core/classes/artifacts/flinklink_jar/flinklink.jar  hadoop@ec2-54-213-47-104.us-west-2.compute.amazonaws.com:

scp -i ~/key/AmidstToolbox.pem core/classes/artifacts/uai2016_jar/uai2016.jar  hadoop@ec2-54-200-118-231.us-west-2.compute.amazonaws.com:


./bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 1024 -c eu.amidst.dataGeneration.NormalizeData ../uai2016.jar hdfs:///uai1K.arff 

flink-0.10.0/bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 4024 -c eu.amidst.modelExperiments.IDAmodelDistributedVMP uai2016.jar hdfs:///uai1K.arff 1000 100 10 0 > output.txt 2>&1

flink-0.10.0/bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 4024 -c eu.amidst.modelExperiments.ParseOutput uai2016.jar file://~/output.txt file://~/parsedOutput.txt


./bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 1024 -c eu.amidst.flinklink.examples.WordCountExample ../flinklink.jar

./bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 4000 -c eu.amidst.flinklink.examples.DynamicParallelVMPExtended ../flinklink.jar 10 10 10000 100 10 10 2 0 true > output_10_10_10K_100_10_10_2_0_1nodes.txt 2>&1


scp —r -i ~/key/AmidstToolbox.pem /Users/ana/huginlib  hadoop@ec2-54-201-244-38.us-west-2.compute.amazonaws.com:

scp -i ~/key/AmidstToolbox.pem ~/key/AmidstToolbox.pem hadoop@ec2-54-213-82-227.us-west-2.compute.amazonaws.com:

scp -i AmidstToolbox.pem hadoop@ec2-54-200-200-223.us-west-2.compute.amazonaws.com:/home/hadoop/taskmanager.log ./salidasIOJarException/

scp -i AmidstToolbox.pem hadoop@ec2-54-213-211-187.us-west-2.compute.amazonaws.com:/var/log/hadoop-yarn/containers/application_1453325855221_0001/container_1453325855221_0001_01_000003/taskmanager.log ./

scp -i ~/key/AmidstToolbox.pem hadoop@ec2-54-201-146-219.us-west-2.compute.amazonaws.com:/home/hadoop/flink-0.10.0/learning* ./errores16nodes/

vi conf/flink-yarn.conf

cd flink-0.10.0
./bin/flink run -m yarn-cluster -yn 1 -ys 8 -yjm 1024 -ytm 10000 -c eu.amidst.flinklink.examples.DynamicParallelVMPExtended ../flinklink.jar 10 10 1000000 100 10 100 2 0 true > output_10_10_1M_100_10_100_2_0_1nodes.txt 2>&1

cd flink-0.10.0
sed -i -e ‘s/\#taskmanager.network.numberOfBuffers:\ 2048/taskmanager.network.numberOfBuffers:\ 12048/g‘ conf/flink-conf.yaml

./bin/flink run -m yarn-cluster -yn 16 -ys 4 -yjm 1024 -ytm 9000 -c eu.amidst.reviewMeeting2016.GenerateData ../reviewMeeting2016.jar 10 100000 10 > output_10_100K_10_5.txt 2>&1
./bin/flink run -m yarn-cluster -yn 16 -ys 8 -yjm 1024 -ytm 19000 -c eu.amidst.reviewMeeting2016.CajaMarDemo ../reviewMeeting2016.jar 10 > learning_10_100K_10.txt 2>&1

./bin/flink run -m yarn-cluster -yn 16 -ys 8 -yjm 1024 -ytm 19000 -c eu.amidst.reviewMeeting2016.CajaMarDemoNB ../reviewMeeting2016.jar 10 > learning_10_100K_10NB.txt 2>&1
./bin/flink run -m yarn-cluster -yn 16 -ys 8 -yjm 1024 -ytm 19000 -c eu.amidst.reviewMeeting2016.CajaMarDemoHNB ../reviewMeeting2016.jar 10 > learning_10_100K_10.txt 2>&1

bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 9000 -c eu.amidst.reviewMeeting2016.GenerateData ../reviewMeeting2016.jar 10 1000 10 > output_10_1K_10.txt 2>&1
./bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 9000 —c eu.amidst.reviewMeeting2016.CajaMarDemoNB  -yD yarn.app.mapreduce.am.env="LD_LIBRARY_PATH=/home/hadoop/huginlib" ../reviewMeeting2016.jar 10 > learning_10_1K_10NB.txt 2>&1

./bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 4000 -c eu.amidst.reviewMeeting2016.CajaMarDemoNB -yD yarn.nodemanager.env-whitelist="LD_LIBRARY_PATH=/home/hadoop/huginlib" ../reviewMeeting2016.jar 2

./bin/flink run -m yarn-cluster -yn 2 -ys 4 -yjm 1024 -ytm 4000 -c eu.amidst.reviewMeeting2016.CajaMarDemoNB -yD yarn.log-aggregation-enable=“true” ../reviewMeeting2016.jar 2

#Logging
./bin/flink run -m yarn-cluster -yn 1 -ys 2 -yjm 1024 -ytm 1024 -c eu.amidst.flinklink.examples.WordCountExample ../flinklink.jar

vi /etc/alternatives/hadoop-conf/yarn-site.xml
yarn.log-aggregation-enable: true
screen
./bin/yarn-session.sh -n 1 -tm 2048 -s 4
CTRL+a 
d
./bin/flink run -yn 1 -ys 4 -yjm 1024 -ytm 1024 -c eu.amidst.flinklink.examples.WordCountExample ../flinklink.jar
screen -r
stop

yarn logs -applicationId application_1454070365245_0004
/var/log/hadoop-yarn/containers/application_1452499404221_0001/container_1452499404221_0001_01_000002
/usr/lib/hadoop-yarn/sbin/
scp -i ~/key/AmidstToolbox.pem -r /Users/ana/Documents/hadoop-2.7.1/sbin/stop-yarn.sh /Users/ana/Documents/hadoop-2.7.1/sbin/start-yarn.sh hadoop@ec2-54-201-44-143.us-west-2.compute.amazonaws.com:
##### Found online to test
/usr/lib/hadoop/sbin/hadoop-daemons.sh stop datanode
/usr/lib/hadoop-yarn/sbin/yarn-daemons.sh stop nodemanager
/usr/lib/hadoop-yarn/sbin/hadoop-daemon.sh stop namenode
/usr/lib/hadoop-yarn/sbin/yarn-daemon.sh stop resourcemanager
/usr/lib/hadoop-mapreduce/sbin/mr-jobhistory-daemon.sh stop historyserver


aws emr modify-cluster-attributes --cluster-id j-3ADLFHRQTLB97 --no-termination-protected
aws emr terminate-clusters --cluster-ids j-3ADLFHRQTLB97 --region us-east-1 


#File to hdfs
/etc/hadoop/conf/hdfs-site.xml # change repetitions to 3
sudo hdfs namenode -format
scp -i ~/key/AmidstToolbox.pem /Users/ana/core/datasets/sampleBatchSize.arff  hadoop@ec2-54-213-80-95.us-west-2.compute.amazonaws.com:
hadoop fs -copyFromLocal sampleBatchSize.arff /sampleBatchSize.arff
hdfs fsck /sampleBatchSize.arff
hdfs dfs -ls /
hadoop fs -setrep -w 3 /sampleBatchSize.arff
hadoop fs -rm /sampleBatchSize.arff

#Hadoop file system

hadoop fs -D fs.local.block.size=134217728 -put local_name remote_location
#dfs.block.size

yarn node -list|sed -n "s/^\(ip[^:]*\):.*/\1/p" | xargs -t -I{} -P10 scp -o StrictHostKeyChecking=no -i AmidstToolbox.pem /etc/alternatives/hadoop-conf/yarn-site.xml hadoop@{}://etc/hadoop/conf/

yarn node -list|sed -n "s/^\(ip[^:]*\):.*/\1/p" | xargs -t -I{} -P10 ssh -o StrictHostKeyChecking=no -i AmidstToolbox.pem hadoop@{} "yarn resourcemanager stop"

#Install R
wget http://lib.stat.cmu.edu/R/CRAN/src/base/R-3/R-3.2.3.tar.gz
tar xzf R-3.2.3.tar.gz
cd R-3-2-3
./configure --with-readline=no --with-x=no
make

scp -i ~/key/AmidstToolbox.pem  core/classes/artifacts/uai2016_jar/uai2016.jar /Users/ana/Dropbox/amidst/toolbox/data_generator_IDA.R /Users/ana/Dropbox/amidst/toolbox/data_generator_SCAI.R hadoop@ec2-54-201-246-216.us-west-2.compute.amazonaws.com:

## NaiveBayesVirtualConceptDriftDetectorTest

./bin/flink run -m yarn-cluster -yn 4 -ys 4 -yjm 1024 -ytm 9000 -c eu.amidst.dataGeneration.GenerateCajaMarData ../uai2016.jar -s 10 -numFiles 3 -RscriptsPath "/home/hadoop" -outputFullPath "/home/hadoop/dataset/noIndex" -seed 0 -addConceptDrift > output_generateDataset.txt 2>&1

./bin/flink run -m yarn-cluster -yn 4 -ys 4 -yjm 1024 -ytm 9000 -c eu.amidst.dataGeneration.NaiveBayesVirtualConceptDriftDetectorTest ../uai2016.jar "/home/hadoop/dataset/noIndex" > output_NaiveBayesVirtualConceptDriftDetectorTest.txt 2>&1

## 
./bin/flink run -m yarn-cluster -yn 4 -ys 4 -yjm 1024 -ytm 9000 -c eu.amidst.dataGeneration.GenerateCajaMarData ../uai2016.jar -s 10 -numFiles 3 -RscriptsPath "/home/hadoop" -outputFullPath "/home/hadoop/dataset/withIndex" -printINDEX -seed 0 -addConceptDrift > output_generateDataset.txt 2>&1

./bin/flink run -m yarn-cluster -yn 4 -ys 4 -yjm 1024 -ytm 9000 -c eu.amidst.dataGeneration.IDAConceptDriftDetectorTest ../uai2016.jar "hdfs:///50K" > output_IDAConceptDriftDetectorTest50K.txt 2>&1

/etc/hadoop/conf/hdfs-site.xml # change repetitions to 3
sudo hdfs namenode -format
hadoop fs -copyFromLocal withIndex/ /withIndex
hdfs fsck /withIndex


-region us-west-2
aws s3 mb s3://amidstdata
aws s3 cp core/extensions/uai2016/doc-experiments/dataGenerationForFlink/IDAlikeData/withoutIndex/  s3://amidstdata  --recursive
hadoop distcp s3://amidstdata/50K hdfs:///data/50K
hadoop S3DistCp s3://amidstdata/50K/MONTH1.arff/name.txt hdfs:///name.txt

scp -i ~/key/AmidstToolbox.pem -r /Users/ana/core/extensions/uai2016/doc-experiments/dataGenerationForFlink/IDAlikeData/withIndex/50K/ hadoop@ec2-54-201-44-143.us-west-2.compute.amazonaws.com:

scp -i ~/key/AmidstToolbox.pem -r hadoop@ec2-54-213-123-199.us-west-2.compute.amazonaws.com:/home/hadoop/small ./


########################## Global scripts
wget https://s3.eu-central-1.amazonaws.com/amidst/start-dfs.sh
wget https://s3.eu-central-1.amazonaws.com/amidst/start-yarn.sh

########################## Env variables are in
cat /etc/default/hadoop

######################### To set lib exec
HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
sudo vi /usr/lib/hadoop-hdfs/bin/hdfs
sudo vi $HADOOP_YARN_HOME/sbin/yarn-daemon.sh
sudo vi /usr/lib/hadoop-yarn/bin/yarn

########################## Try to set them in
vi /etc/hadoop/conf/hadoop-env.sh 
/etc/hadoop/conf/yarn-env.sh
/etc/hadoop/mapred-env.sh

########################## JAVA_HOME
export JAVA_HOME=/etc/alternatives/jre

########################## LOG-AGGREGATION TO TRUE 
vi /etc/alternatives/hadoop-conf/yarn-site.xml

########################## START YARN CLUSTER
sudo hdfs namenode -format -Y

sudo $HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start namenode

sudo $HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start datanode

sudo $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start resourcemanager

sudo $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start nodemanager 

sudo $HADOOP_YARN_HOME/sbin/yarn-daemon.sh start proxyserver --config $HADOOP_CONF_DIR

sudo /usr/lib/hadoop-mapreduce/sbin/mr-jobhistory-daemon.sh start historyserver --config $HADOOP_CONF_DIR

########################### WORD COUNT
./bin/flink run -m yarn-cluster -yn 1 -ys 2 -yjm 1024 -ytm 1024 -c eu.amidst.flinklink.examples.WordCountExample ../flinklink.jar

########################### CHECK LOGS
yarn logs -applicationId application_1454492244860_0001

########################### STOP YARN CLUSTER
sudo $HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs stop namenode

sudo $HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs stop datanode

sudo $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR stop resourcemanager

sudo $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR stop nodemanager

sudo $HADOOP_YARN_HOME/sbin/yarn-daemon.sh stop proxyserver --config $HADOOP_CONF_DIR

sudo /usr/lib/hadoop-mapreduce/sbin/mr-jobhistory-daemon.sh stop historyserver --config $HADOOP_CONF_DIR


yarn node -list|sed -n "s/^\(ip[^:]*\):.*/\1/p" | xargs -t -I{} -P10 scp -o StrictHostKeyChecking=no -i ~/AmidstToolbox.pem /etc/alternatives/hadoop-conf/yarn-site.xml hadoop@{}:

yarn node -list|sed -n "s/^\(ip[^:]*\):.*/\1/p" | xargs -t -I{} -P10 ssh -o StrictHostKeyChecking=no -i ~/AmidstToolbox.pem hadoop@{} "yarn resourcemanager stop"

http://ec2-54-213-82-227.us-west-2.compute.amazonaws.com:8088/

#Quick hadoop test
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount s3://amidst2/emr_bootstrap_java_8_emr400.sh hdfs:///tmp/output


#Example how to show logs in s3
aws s3 ls --recursive s3://amidst2/logsForClusters/j-3GF5GFR95HVHX/containers/application_1455112515575_0002