\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeY format
\usepackage{geometry}                		% See geom\dagetry.pdf to learn the layout options. There are lots.
\geometry{a4paper}                   		% ... or a4paper or a5paper or ... 
%\geometrx{landscape}                		% Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an emptx line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatey; use eps in DVI ye
\usepackage{array}							% TeY will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb,amsmath}
\usepackage{cite}
\usepackage[final]{fixme}
\usepackage{pdfpages}
\usepackage{tabulary}
\usepackage{fancyheadings}
\usepackage{lastpage}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usepackage{float}
\usepackage{hyperref}
\usepackage{url}
\usepackage{multirow}

\parskip 6pt % 1pt = 0.351 mm
\parindent 0pt

%\title{Requirement Engineering Process in AMIDST}
%\author{The handsome AMIDST guys et. al.}
%\date{Latest version, \today}							% Activate to display a given date or no date


%\setcounter{page}{2}
\newcommand{\drop}[1]{}
\newcommand{\bm}{\mathbf}

\newcommand{\bu}[1]{\mathbf{#1}}
\newcommand{\bv}[1]{\bm{#1}}

\newcommand{\todo}[1]{{\bf [TODO: #1]}}

\DeclareMathOperator*{\E}{\mbox{\large E}}

\newcommand{\me}{\mathrm{e}}

\numberwithin{figure}{section}
\numberwithin{equation}{section}
\numberwithin{table}{section}

\usepackage{pdfpages}

\begin{document}

%-----------------------------------------------------------------------------------------------------------------------------------
\section{A binary child given a binary parent}
%-----------------------------------------------------------------------------------------------------------------------------------

Let $X$ and $Y$ be two binary variables. The log-conditional probability of the child-node $X$ given its parent-node $Y$ is expressed as follows:

\begin{eqnarray*}
\ln p(X \mid Y) =  I(X= x^1) I(Y= y^1) \ln p_{x^1 \mid y^1} + I(X=x^2) I(Y= y^1) \ln p_{x^2 \mid y^1} \\
+ I(X=x^1) I(Y= y^2) \ln p_{x^1 \mid y^2} + I(X=x^2) I(Y= y^2) \ln p_{x^2 \mid y^2}
\end{eqnarray*}

This conditional probability can be expressed in different exponential forms as follows:


\begin{itemize}

\item \textbf{First form}:

\begin{eqnarray*}
\ln p(X \mid Y) &=& \theta^T s(X,Y) - A(\theta) \\
&=&
\begin{pmatrix}
\ln p_{x^1 \mid y^1}\\
\ln p_{x^2 \mid y^1}\\
\ln p_{x^1 \mid y^2}\\
\ln p_{x^2 \mid y^2}
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1)I(Y=y^1) \\
I(X=x^2)I(Y=y^1) \\
I(X=x^1)I(Y=y^2) \\
I(X=x^2)I(Y=y^2) 
\end{pmatrix}
- 0\\
&=&
\begin{pmatrix}
\theta_{11}\\
\theta_{21}\\
\theta_{12}\\
\theta_{22}
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1)I(Y=y^1) \\
I(X=x^2)I(Y=y^1) \\
I(X=x^1)I(Y=y^2) \\
I(X=x^2)I(Y=y^2) 
\end{pmatrix}
- 0
\end{eqnarray*}

\item \textbf{Second form}:

\begin{eqnarray*}
\ln p(X \mid Y) &=& \theta(Y)^Ts(X) - A(Y) \\
&=&
\begin{pmatrix}
I(Y=y^1)\ln p_{x^1 \mid y^1}  + I(Y=y^2)\ln p_{x^1 \mid y^2}\\
I(Y=y^1)\ln p_{x^2 \mid y^1}  + I(Y=y^2)\ln p_{x^2 \mid y^2}
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1) \\
I(X=x^2)
\end{pmatrix}
- 0 \\
&=&
\begin{pmatrix}
m^Y_1\cdot\theta_{11}  + m^Y_2\cdot\theta_{12}\\
m^Y_1\cdot\theta_{21}  + m^Y_2\cdot\theta_{22}
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1) \\
I(X=x^2)
\end{pmatrix}
- 0 
\end{eqnarray*}

\item \textbf{Third form}:

\begin{eqnarray*}
\ln p(X \mid Y) &=& \theta(X)^T s(Y) - A(X) \\
&=&
\begin{pmatrix}
I(X=x^1)\ln p_{x^1 \mid y^1}  + I(X=x^2)\ln p_{x^2 \mid y^1}\\
I(X=x^1)\ln p_{x^1 \mid y^2}  + I(X=x^2)\ln p_{x^2 \mid y^2}
\end{pmatrix}^T
\begin{pmatrix}
I(Y=y^1) \\
I(Y=y^2)
\end{pmatrix}
- 0\\
&=&
\begin{pmatrix}
m^X_1 \cdot \theta_{11}  +  m^X_2\cdot \theta_{21}\\
m^X_1 \cdot \theta_{12}  + m^X_2 \cdot \theta_{22}
\end{pmatrix}^T
\begin{pmatrix}
I(Y=y^1) \\
I(Y=y^2)
\end{pmatrix}
- 0
\end{eqnarray*}

\end{itemize}

\newpage
%-----------------------------------------------------------------------------------------------------------------------------------
\section{A multinomial child given a set of multinomial parents}
%-----------------------------------------------------------------------------------------------------------------------------------

Let $X$ be a multinomial variable with $k$ possible values such that $k \geq 2$, and let $\mathbf{Y} =\{Y_1,\ldots,Y_n\}$ denote the set of parents of $X$, such that all of them are multinomial. Each parent $Y_i$, $1 \geq i \geq n$, has $r_i$ possible values or states such that $r_i \geq 2$. A parental configuration for the child-node $X$ is then a set of $n$ elements $\{Y_1 = y_1^{v}, \ldots, Y_i = y_i^{v},\ldots, Y_n = y_n^{v} \}$ such that $y_i^{v}$ denotes a potential value of variable $Y_i$ such that  $1 \leq v \leq r_i$. Let $q = r_1 \times \ldots \times r_n$ denote the total number of parental configurations, and let $\mathbf{y}^l$ denote the $l^{th}$ parental configuration such that $1 \leq l \leq q$.

The log-conditional probability of the child-node $X$ given its parent-nodes $\mathbf{Y}$ can be expressed as follows:

$$ \ln p(X \mid \mathbf{Y}) = \sum_{j=1}^k \sum_{l=1}^q I(X=x^j) I(\mathbf{Y} =\mathbf{y}^l) \ln p_{x^j  \mid \mathbf{y}^l} $$

Similarly the above log-conditional probability can be expressed in the following exponential forms:

\begin{itemize}

\item \textbf{First form}:

\begin{eqnarray*}
\ln p(X \mid \mathbf{Y}) &=& \theta^T s(X,\mathbf{Y}) - A(\theta) \\\\
&=&
\begin{pmatrix}
\ln p_{x^1\mid \mathbf{y}^1}\\
\vdots \\
\ln p_{x^1\mid \mathbf{y}^q}\\
\vdots \\
\ln p_{x^k\mid \mathbf{y}^1}\\
\vdots \\
\ln p_{x^k\mid \mathbf{y}^q}\\
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1)I(\mathbf{Y}=\mathbf{y}^1) \\
\vdots \\
I(X=x^1)I(\mathbf{Y}=\mathbf{y}^q)\\
\vdots \\
I(X=x^k)I(\mathbf{Y}=\mathbf{y}^1) \\
\vdots \\
I(X=x^k)I(\mathbf{Y}=\mathbf{y}^q)
\end{pmatrix}
- 0 \\\\
&=&
\begin{pmatrix}
\theta_{11}\\
\vdots \\
\theta_{1q}\\
\vdots \\
\theta_{k1}\\
\vdots \\
\theta_{kq}\\
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1) I(\mathbf{Y}=\mathbf{y}^1) \\
\vdots \\
I(X=x^1) I(\mathbf{Y}=\mathbf{y}^q)\\
\vdots \\
I(X=x^k) I(\mathbf{Y}=\mathbf{y}^1) \\
\vdots \\
I(X=x^k) I(\mathbf{Y}=\mathbf{y}^q)
\end{pmatrix}
- 0
\end{eqnarray*}

\vspace{0.5in}
\item \textbf{Second form}:

\begin{eqnarray*}
\ln p(X \mid \mathbf{Y}) &=& \theta(\mathbf{Y})^Ts(X) - A(\mathbf{Y}) \\ \\
&=&
\begin{pmatrix}
I(\mathbf{Y}=\mathbf{y}^1) \ln p_{x^1\mid \mathbf{y}^1} + \ldots + I(\mathbf{Y}=\mathbf{y}^q)\ln p_{x^1\mid \mathbf{y}^q}\\
\vdots \\
I(\mathbf{Y}=\mathbf{y}^1) \ln p_{x^k\mid \mathbf{y}^1} + \ldots + I(\mathbf{Y}=\mathbf{y}^q)\ln p_{x^k\mid \mathbf{y}^q}\\
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1) \\
\vdots \\
I(X=x^k) 
\end{pmatrix}
- 0 \\ \\
&=&
\begin{pmatrix}
\mathbf{m}^{\mathbf{Y}}_1 \cdot \theta_{11}  + m^{\mathbf{Y}}_q \cdot \theta_{1q} \\
\vdots \\
\mathbf{m}^{\mathbf{Y}}_1 \cdot \theta_{k1}  + m^{\mathbf{Y}}_q \cdot \theta_{kq}
\end{pmatrix}^T
\begin{pmatrix}
I(X=x^1) \\
\vdots \\
I(X=x^k)
\end{pmatrix}
- 0 
\end{eqnarray*}

\noindent such that $\mathbf{m}^{\mathbf{Y}}_1 = \prod_{i=1}^n I( Y_i = y_i^1) = \prod_{i=1}^n m^{Y_i}_1$ denotes the expected sufficient statistics for the first parental configuration, and $\mathbf{m}^{\mathbf{Y}}_q = \prod_{i=1}^n I( Y_i = y_i^{r_i})  = \prod_{i=1}^n m^{Y_i}_{r_i} $ denotes the expected sufficient statistics for the last parental configuration.

\vspace{0.5in}
\item \textbf{Third form}:

\begin{eqnarray*}
\ln p(X\mid \mathbf{Y}) &=& \theta(X)^T s(\mathbf{Y}) - A(X) \\ \\
&=&
\begin{pmatrix}
I(X=x^1)  \ln p_{x^1\mid \mathbf{y}^1}  + \ldots + I(X=x^k)  \ln p_{x^k\mid \mathbf{y}^1} \\
\vdots \\
I(X=x^1)  \ln p_{x^1\mid \mathbf{y}^q}  + \ldots + I(X=x^k)  \ln p_{x^k\mid \mathbf{y}^q}
\end{pmatrix}^T
\begin{pmatrix}
I(\mathbf{Y}=\mathbf{y}^1) \\
\vdots \\
I(\mathbf{Y}=\mathbf{y}^q)
\end{pmatrix}
- 0\\ \\
&=&
\begin{pmatrix}
m^X_1 \cdot \theta_{11}  +  \ldots + m^X_k \cdot \theta_{k1}\\
\vdots \\
m^X_1 \cdot \theta_{1q}   + \ldots + m^X_k \cdot \theta_{kq}
\end{pmatrix}^T
\begin{pmatrix}
I(\mathbf{Y}=\mathbf{y}^1) \\
\vdots \\
I(\mathbf{Y}=\mathbf{y}^q)
\end{pmatrix}
- 0
\end{eqnarray*}

%----------------------------------------- with one parent

\begin{eqnarray*}
\ln p(X\mid \mathbf{Y}) &=& \theta(X, \mathbf{Y'} )^T s(Y_i) - A(X) ~~\textrm{such~that} ~\mathbf{Y'} = \mathbf{Y} \setminus Y_i \\ \\
&= &
\begin{pmatrix}
\! m^X_1 I(\mathbf{Y'} =\mathbf{y'}^1) \ln p_{x^1\mid \mathbf{y'}^1}  + \ldots + m^X_k I(\mathbf{Y'} =\mathbf{y'}^1) \ln p_{x^k\mid \mathbf{y'}^1}  \! \\
\vdots \\
\! m^X_1 I(\mathbf{Y'} =\mathbf{y'}^{q'})  \ln p_{x^1\mid \mathbf{y'}^{q'}}  + \ldots + m^X_k I(\mathbf{Y'} =\mathbf{y'}^{q'}) \ln p_{x^k\mid \mathbf{y'}^{q'}}\! 
\end{pmatrix}^T \!
\begin{pmatrix}
I(Y_i=y_i^1) \! \\
\vdots \\
I(Y_i=y_i^{r_i}) \!
\end{pmatrix}
\! - 0 \! \\ \\
&=&
\begin{pmatrix}
\! m^X_1 \cdot  \mathbf{m}^{\mathbf{Y'}}_1 \cdot \theta'_{11}  +  \ldots + m^X_k \cdot \mathbf{m}^{\mathbf{Y'}}_1 \cdot \theta'_{k1}\\
\vdots \\
\! m^X_1 \cdot  \mathbf{m}^{\mathbf{Y'}}_{q'} \cdot \theta'_{1q'}   + \ldots + m^X_k \cdot  \mathbf{m}^{\mathbf{Y'}}_{q'} \cdot \theta'_{kq'}
\end{pmatrix}^T \!
\begin{pmatrix}
I(Y_i=y_i^1) \! \\
\vdots \\
I(Y_i=y_i^{r_i}) \!
\end{pmatrix}
- 0 \!
\end{eqnarray*}


\noindent where $\mathbf{m}^{\mathbf{Y'}}_1 =  I(\mathbf{Y'} =\mathbf{y'}^1) = I( Y_1 = y_1^1) \cdot \ldots I( Y_{i-1} = y_{i-1}^1) \cdot I( Y_{i+1}  = y_{i+1}^1) \cdot \ldots I( Y_{n}  = y_{n}^1)$ denotes the expected sufficient statistics for the first configuration of the parent set $\mathbf{Y'} = \mathbf{Y} \setminus Y_i$, and $\mathbf{m}^{\mathbf{Y'}}_{q'} = I(\mathbf{Y'} =\mathbf{y'}^{q'}) = I( Y_1 = y_1^{q'}) \cdot \ldots I( Y_{i-1} = y_{i-1}^{q'}) \cdot I( Y_{i+1}  = y_{i+1}^{q'}) \cdot \ldots I( Y_{n}  = y_{n}^{q'})$ denotes the expected sufficient statistics for the last configuration of the parent set $\mathbf{Y'}$, with $q' = q / r_i$ denotes the total number of configurations of the parent set $\mathbf{Y'}$.




\end{itemize}


\newpage
%-----------------------------------------------------------------------------------------------------------------------------------
\section{A normal child given a set of normal parents}
%-----------------------------------------------------------------------------------------------------------------------------------

Let $X$ be a normal variable and $ \mathbf{Y} = \{Y_1,\ldots,Y_n\}$ denote the set of parents of $X$, such that all of them are normal. 

The log-conditional probability of $X$ given its parents $\mathbf{Y}$ can be expressed as follows:

$$ \ln p(X|Y_1,\ldots,Y_n) = \ln \left(\frac{1}{\sigma \sqrt{2(\beta_0+\sum_i^n \beta_i Y_i )}} \me^{-\frac{(y-(\beta_0+\sum_i^n \beta_i Y_i))^2}{2\sigma^2}} \right)$$


Similarly the above log-conditional probability can be expressed in the following exponential forms:

\begin{itemize}
\item \textbf{First form - Joint suff. stat. (Maxim. Likelihood)}:

\begin{eqnarray*}
\ln p(X \mid \mathbf{Y}) &=& \theta^T s(X,\mathbf{Y}) - A(\theta) + h(\mathbf{Y})\\\\
&=&
\begin{pmatrix}
\frac{-1}{2\sigma^2} &=& \theta_{\mbox{-}1} \\
\frac{\beta_0}{\sigma^2} &=& \theta_0 \\
\frac{\beta_1}{\sigma^2} &=& \theta_1 \\
\vdots\\
\frac{\beta_n}{\sigma^2} &=& \theta_n \\\\
\frac{-\beta_0\beta_1}{2\sigma^2} &=&\theta_{01} \\
\vdots\\
\frac{-\beta_0\beta_n}{2\sigma^2} &=& \theta_{0n} \\
\frac{-\beta_1^2}{2\sigma^2} &=& \theta_{1^2} \\
\vdots \\
\frac{-\beta_n^2}{2\sigma^2} &=& \theta_{n^2} \\
\frac{-\beta_1\beta_2}{2\sigma^2} &=& \theta_{12} \\
\vdots\\
\frac{-\beta_1\beta_n}{2\sigma^2} &=& \theta_{1n} \\
\vdots\\
\frac{-\beta_{n-1}\beta_n}{2\sigma^2} &=&\theta_{n\mbox{-}1n} \\
\end{pmatrix}^T
\begin{pmatrix}
X^2   &=& m_{X^2}\\
X     &=& m_{X}\\
XY_1  &=& m_{XY_1}\\
\vdots\\
XY_n  &=& m_{XY_n}\\
Y_1   &=& m_{Y_1}\\
\vdots\\
Y_n   &=& m_{Y_n}\\
Y_1^2 &=& m_{Y_1^2}\\
\vdots\\
Y_n^2 &=& m_{Y_n^2}\\
Y_1Y_2&=& m_{Y_1Y_2}\\
\vdots\\
Y_1Y_n &=& m_{Y_1Y_n}\\
\vdots\\
Y_{n\mbox{-}1}Y_n &=& m_{Y_{n\mbox{-}1}Y_{n}}
\end{pmatrix}
- \left( \frac{\beta_0^2}{2\sigma^2} + \ln{\sigma}\right) + \frac{1}{\ln{\sqrt{2\mu_{X|Y}}}}
\end{eqnarray*}

where $\mu_{X|Y} = \beta_0+\sum_i^n{\beta_i Y_i}$

\begin{itemize}
\item \textbf{From moment to natural parameters: (matrix representation)}


\begin{eqnarray*}
\ln p(X \mid \mathbf{Y}) &=& \theta^T s(X,\mathbf{Y}) - A(\theta) + h(\mathbf{Y})\\\\
&=&
\begin{pmatrix}
\beta_0 (\sigma^2)^{-1} &=& \theta_{0} \\
-\beta_0 \beta^T (2\sigma^2)^{-1} &=& \theta_{\beta_0 \beta^T} \\
-(2\sigma^2)^{-1} &=& \theta_{\mbox{-}1} \\
\beta (\sigma^2)^{-1} &=& \theta_{\beta} \\
-\beta' \beta^T (2\sigma^2)^{-1} &=& \theta_{\beta \beta^T} \\
\end{pmatrix}^T
\begin{pmatrix}
X   &=& \E(X)\\
Y   &=& \E(Y)\\
XX^T   &=& \E(X)E(X)^T\\
YX^T   &=& \E(YX^T)\\
YY^T   &=& \E(YY^T)\\
\end{pmatrix}
\\
&-& \left( \frac{\beta_0^2}{2\sigma^2} + \ln{\sigma}\right)  + \frac{1}{\ln{\sqrt{2\mu_{X|Y}}}}
\end{eqnarray*}

where

\begin{tabular}{p{4cm}p{4cm}}
\begin{eqnarray*}
\beta &=& 
\begin{pmatrix}
\beta_1\\
\vdots\\
\beta_n\\
\end{pmatrix}
\end{eqnarray*}
&
\begin{eqnarray*}
Y &=& 
\begin{pmatrix}
Y_1\\
\vdots\\
Y_n\\
\end{pmatrix}
\end{eqnarray*}
\\
\end{tabular}


\begin{itemize}


\item FIRST STEP: 
\begin{eqnarray*}
\mu_X &=& E(X)\\
\mu_\mathbf{Y} &=& \E(Y)\\
\Sigma_{XX} &=&  \E(XX^T) - \E(X)\E(X)^T\\
\Sigma_{\mathbf{YY}} &=&  \E(YY^T) - \E(Y)\E(Y)^T \\
\Sigma_{X\mathbf{Y}} &=&  \E(YX^T)^T - \E(X)\E(Y)^T\\
\Sigma_{\mathbf{Y}X} &=&  \E(YX^T) - \E(Y)\E(X)
\end{eqnarray*}

\item SECOND STEP (Theorem 7.4 in page 253, Koller \& Friedman):
\begin{eqnarray*}
\beta_0 &=& \mu_X - \Sigma_{X\mathbf{Y}}\Sigma^{-1}_{\mathbf{YY}}\mu_\mathbf{Y}\\
\beta   &=& \Sigma_{X\mathbf{Y}}\Sigma^{-1}_{\mathbf{YY}} \\
\sigma^2 &=& \Sigma_{XX} - \Sigma_{XY}\Sigma^{-1}_{YY}\Sigma_{YX}
\end{eqnarray*}

All natural parameters $\theta$ can now be calculated considering these equations.
\end{itemize}

\item \textbf{From natural to moment parameters:}
Via inference.

\end{itemize}

\vspace{0.5in}
\item \textbf{Second form}:

\begin{eqnarray*}
\ln p(X\mid \mathbf{Y}) &=& \theta(\mathbf{Y})^T s(X) - A \big(\theta(\mathbf{Y})\big) + h(\mathbf{Y})\\\\
&=&
\begin{pmatrix}
\frac{\mu_{X|Y}}{\sigma^2}\\
\frac{-1}{2\sigma^2}\\
\end{pmatrix}^T
\begin{pmatrix}
X\\
X^2\\
\end{pmatrix}
- \left(\frac{\mu_{X|Y}^2}{2\sigma^2} + \ln{\sigma}\right) + \ln{\frac{1}{\sqrt{2\mu_{X|Y}}}} \\\\
&=&
\begin{pmatrix}
\theta_0+\sum_i^n\theta_i m^{Y_i}\\
\theta_{\mbox{-}1}\\
\end{pmatrix}^T
\begin{pmatrix}
X\\
X^2\\
\end{pmatrix}
- \left(\frac{\ln{(2\theta_{\mbox{-}1}})}{2}-\theta_{\mbox{-}1}\left(\theta_0+\sum_i^n\theta_i m^{Y_i}\right)^2 \right) \\
&+&
 \ln{\frac{1}{\sqrt{2(\theta_0+\sum_i^n\theta_i m^{Y_i})}}} 
\end{eqnarray*}



\vspace{0.2in}
\item \textbf{Third form}:

\begin{eqnarray*}
\ln p(X\mid \mathbf{Y}) &=& \theta(X)^T s(\mathbf{Y}) - A \big(\theta(X) \big) + h(\mathbf{Y})\\\\
&=&
\begin{pmatrix}
-\frac{\beta_1^2}{2\sigma^2}\\
\cdots\\
-\frac{\beta_n^2}{2\sigma^2}\\
\frac{\beta_1(X-\beta_0)}{\sigma^2}\\
\cdots\\
\frac{\beta_n(X-\beta_0)}{\sigma^2}\\
-\frac{\beta_1\beta_2}{\sigma^2}\\
\cdots\\
-\frac{\beta_1\beta_n}{\sigma^2}\\
\cdots\\
-\frac{\beta_{n-1}\beta_n}{\sigma^2}
\end{pmatrix}^T
\begin{pmatrix}
Y_1^2\\
\cdots\\
Y_n^2\\
Y_1\\
\cdots\\
Y_n\\
Y_1 Y_2\\
\cdots\\
Y_1 Y_n\\
\cdots\\
Y_{n-1}Y_{n}\\
\end{pmatrix}
- \left( \frac{(X-\beta_0)^2}{\sigma^2} + \ln{\sigma} \right) + \frac{1}{\ln{\sqrt{2\mu_{X|Y}}}}\\\\
&=&
\begin{pmatrix}
\theta_{1^2}\\
\cdots\\
\theta_{n^2}\\
\theta_1 m^X+\theta_{01}\\
\cdots\\
\theta_n m^X+\theta_{0n}\\
\theta_{12}\\
\cdots\\
\theta_{1n}\\
\cdots\\
\theta_{n\mbox{-}1n}
\end{pmatrix}^T
\begin{pmatrix}
Y_1^2\\
\cdots\\
Y_n^2\\
Y_1\\
\cdots\\
Y_n\\
Y_1 Y_2\\
\cdots\\
Y_1 Y_n\\
\cdots\\
Y_{n-1}Y_{n}\\
\end{pmatrix}
- \left( \frac{X^2 -2X\beta_0 +\beta_0^2}{\sigma^2} + \ln{\sigma} \right) + \frac{1}{\ln{\sqrt{2\mu_{X|Y}}}}\\
&=&
\begin{pmatrix}
\theta_{1^2}\\
\cdots\\
\theta_{n^2}\\
\theta_1 m^X+\theta_{01}\\
\cdots\\
\theta_n m^X+\theta_{0n}\\
\theta_{12}\\
\cdots\\
\theta_{1n}\\
\cdots\\
\theta_{n\mbox{-}1n}
\end{pmatrix}^T
\begin{pmatrix}
Y_1^2\\
\cdots\\
Y_n^2\\
Y_1\\
\cdots\\
Y_n\\
Y_1 Y_2\\
\cdots\\
Y_1 Y_n\\
\cdots\\
Y_{n-1}Y_{n}\\
\end{pmatrix}
- \left( (-2\beta_{\mbox{-}1}m^{X^2} - 2m^{X}\beta_0 - \frac{1}{2}\beta_0^2 \beta_{\mbox{-}1}^{-1}) + \frac{\ln{(2\theta_{\mbox{-}1}})}{2} \right)\\
&+&
\ln{\frac{1}{\sqrt{2(\theta_0+\sum_i^n\theta_i m^{Y_i})}}} 
\end{eqnarray*}

\end{itemize}

\newpage
%-----------------------------------------------------------------------------------------------------------------------------------
\section{A base distribution given a binary parent}
%-----------------------------------------------------------------------------------------------------------------------------------

Let $X$ be any base distribution variable, and let $Y$ be a binary variable. The log-conditional probability of the child-node $X$ given its binary parent-node $Y$ is expressed as follows:

\begin{eqnarray*}
\ln p(X \mid Y) =  I(Y= y^1) \ln p_{X \mid y^1} + I(Y= y^2) \ln p_{X \mid y^2} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\
= I(Y= y^1)  \Big(\theta_{X1} \cdot s(X) - A(\theta_{X1})\Big) +  I(Y= y^2) \Big(\theta_{X2} \cdot s(X) - A(\theta_{X2})\Big) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\
= I(Y=y^1) \cdot \theta_{X1} \cdot s(X) - I(Y=y^1) \cdot A(\theta_{X1}) +  I(Y=y^2) \cdot \theta_{X2} \cdot s(X) - I(Y=y^2) \cdot A(\theta_{X2})
\end{eqnarray*}

This conditional probability can be expressed in different exponential forms as follows:

\begin{itemize}

\item \textbf{First form}:

\begin{eqnarray*}
\ln p(X \mid Y) &=& \theta^T s(X,Y) - A(\theta) \\
&=&
\begin{pmatrix}
- A(\theta_{X1}) \\
- A(\theta_{X2}) \\
\theta_{X1} \\
\theta_{X2}
\end{pmatrix}^T
\begin{pmatrix}
I(Y=y^1) \\
I(Y=y^2) \\
s(X) \cdot I(Y=y^1) \\
s(X) \cdot I(Y=y^2)
\end{pmatrix}
- 0 
\end{eqnarray*}

\item \textbf{Second form}:

\begin{eqnarray*}
\ln p(X \mid Y) &=& \theta(Y)^Ts(X) - A(Y) \\
&=&
\begin{pmatrix}
I(Y=y^1)\\
I(Y=y^2)\\
I(Y=y^1) \cdot \theta_{X1}\\
I(Y=y^2) \cdot \theta_{X2}
\end{pmatrix}^T
\begin{pmatrix}
- A(\theta_{X1}) \\
- A(\theta_{X2}) \\
s(X) \\
s(X) 
\end{pmatrix}
- 0 \\\\
&=&
\begin{pmatrix}
m^Y_1\\
m^Y_2 \\
m^Y_1 \cdot \theta_{X1}\\
m^Y_2 \cdot \theta_{X2}
\end{pmatrix}^T
\begin{pmatrix}
- A(\theta_{X1}) \\
- A(\theta_{X2}) \\
s(X) \\
s(X) 
\end{pmatrix}
- 0 
\end{eqnarray*}

\item \textbf{Third form}:

\begin{eqnarray*}
\ln p(X \mid Y) &=& \theta(X)^T s(Y) - A(X) \\
&=&
\begin{pmatrix}
- A(\theta_{X1}) \\
- A(\theta_{X2})\\
s(X) \cdot \theta_{X1}\\
s(X) \cdot \theta_{X2}
\end{pmatrix}^T
\begin{pmatrix}
I(Y=y^1) \\
I(Y=y^2) \\
I(Y=y^1) \\
I(Y=y^2)
\end{pmatrix}
- 0
\end{eqnarray*}

\end{itemize}

\newpage
%-----------------------------------------------------------------------------------------------------------------------------------
\section{A base distribution given a set of multinomial parents}
%-----------------------------------------------------------------------------------------------------------------------------------

Let $X$ be any base distribution, and let $\mathbf{Y} =\{Y_1,\ldots,Y_n\}$ denote the set of parents of $X$, such that all of them are multinomial. Each parent $Y_i$, $1 \geq i \geq n$, has $r_i$ possible values or states such that $r_i \geq 2$. A parental configuration for the child-node $X$ is then a set of $n$ elements $\{Y_1 = y_1^{v}, \ldots, Y_i = y_i^{v},\ldots, Y_n = y_n^{v} \}$ such that $y_i^{v}$ denotes a potential value of variable $Y_i$ such that  $1 \leq v \leq r_i$. Let $q = r_1 \times \ldots \times r_n$ denote the total number of parental configurations, and let $\mathbf{y}^l$ denote the $l^{th}$ parental configuration such that $1 \leq l \leq q$.

The log-conditional probability of the child-node $X$ given its parent-nodes $\mathbf{Y}$ can be expressed as follows:

\begin{eqnarray*}
\ln p(X \mid Y) =  \sum_{l=1}^q I(\mathbf{Y} =\mathbf{y}^l) \cdot \ln p_{X \mid \mathbf{y}^l} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\
= \sum_{l=1}^q I(\mathbf{Y} =\mathbf{y}^l) \cdot \Big(  \theta_{Xl}   \cdot  s(X)  \cdot  A(\theta_{Xl}) \Big)~~~~~~~~~~~~~\\
= \sum_{l=1}^q I(\mathbf{Y} =\mathbf{y}^l) \cdot \theta_{Xl} \cdot s(X) - I(\mathbf{Y} =\mathbf{y}^l) \cdot A(\theta_{Xl})
\end{eqnarray*}

This conditional probability can be expressed in different exponential forms as follows:

\begin{itemize}

\item \textbf{First form}:

\begin{eqnarray*}
\ln p(X \mid \mathbf{Y}) &=& \theta^T s(X,\mathbf{Y}) - A(\theta) \\
&=&
\begin{pmatrix}
- A(\theta_{X1}) \\
\vdots \\
- A(\theta_{Xq}) \\
\theta_{X1} \\
\vdots \\
\theta_{Xq}
\end{pmatrix}^T
\begin{pmatrix}
I(\mathbf{Y} =\mathbf{y}^1) \\
\vdots \\
I(\mathbf{Y} =\mathbf{y}^q) \\
s(X) \cdot I(\mathbf{Y} =\mathbf{y}^1) \\
\vdots \\
s(X) \cdot I(\mathbf{Y} =\mathbf{y}^q)
\end{pmatrix}
- 0 
\end{eqnarray*}

\item \textbf{Second form}:

\begin{eqnarray*}
\ln p(X \mid \mathbf{Y} ) &=& \theta(\mathbf{Y} )^T s(X) - A(\mathbf{Y} ) \\
&=&
\begin{pmatrix}
I(\mathbf{Y} =\mathbf{y}^1)\\
\vdots \\
I(\mathbf{Y} =\mathbf{y}^q)\\
I(\mathbf{Y} =\mathbf{y}^1) \cdot \theta_{X1}\\
\vdots \\
I(\mathbf{Y} =\mathbf{y}^q) \cdot \theta_{Xq}
\end{pmatrix}^T
\begin{pmatrix}
- A(\theta_{X1}) \\
\vdots \\
- A(\theta_{Xq}) \\
s(X) \\
\vdots \\
s(X) 
\end{pmatrix}
- 0 \\\\
&=&
\begin{pmatrix}
\mathbf{m}^\mathbf{Y}_1\\
\vdots \\
\mathbf{m}^\mathbf{Y}_q \\
\mathbf{m}^\mathbf{Y}_1 \cdot \theta_{X1}\\
\vdots \\
\mathbf{m}^\mathbf{Y}_q \cdot \theta_{Xq}
\end{pmatrix}^T
\begin{pmatrix}
- A(\theta_{X1}) \\
\vdots \\
- A(\theta_{Xq}) \\
s(X) \\
\vdots \\
s(X) 
\end{pmatrix}
- 0 
\end{eqnarray*}

\item \textbf{Third form}:

\begin{eqnarray*}
\ln p(X \mid \mathbf{Y}) &=& \theta(X)^T s(\mathbf{Y}) - A(X) \\
&=&
\begin{pmatrix}
- A(\theta_{X1}) \\
\vdots \\
- A(\theta_{Xq})\\
s(X) \cdot \theta_{X1}\\
\vdots \\
s(X) \cdot \theta_{Xq}
\end{pmatrix}^T
\begin{pmatrix}
I(\mathbf{Y} =\mathbf{y}^1) \\
\vdots \\
I(\mathbf{Y} =\mathbf{y}^q) \\
I(\mathbf{Y} =\mathbf{y}^1) \\
\vdots \\
I(\mathbf{Y} =\mathbf{y}^q)
\end{pmatrix}
- 0
\end{eqnarray*}

\end{itemize}


%----------------------------------------- with one parent

\begin{eqnarray*}
\ln p(X\mid \mathbf{Y}) &=& \theta(X, \mathbf{Y'} )^T s(Y_i) - A(X) ~~\textrm{such~that} ~\mathbf{Y'} = \mathbf{Y} \setminus Y_i \\ \\
&=&
\begin{pmatrix}
- A(\theta_{X1}) \\
\vdots \\
- A(\theta_{Xq})\\
\! s(X) \cdot  \mathbf{m}^{\mathbf{Y'}}_1 \cdot \theta'_{X1}  +  \ldots + s(X) \cdot \mathbf{m}^{\mathbf{Y'}}_1 \cdot \theta'_{X1}\\
\vdots \\
\! s(X) \cdot  \mathbf{m}^{\mathbf{Y'}}_{q'} \cdot \theta'_{Xq'}   + \ldots + s(X) \cdot  \mathbf{m}^{\mathbf{Y'}}_{q'} \cdot \theta'_{Xq'}
\end{pmatrix}^T \!
\begin{pmatrix}
I(Y_i=y_i^1) \! \\
\vdots \\
I(Y_i=y_i^{r_i}) \!\\
I(Y_i=y_i^1) \! \\
\vdots \\
I(Y_i=y_i^{r_i}) \!
\end{pmatrix}
- 0 \!
\end{eqnarray*}


\newpage
%-----------------------------------------------------------------------------------------------------------------------------------
\section*{Notations}
%-----------------------------------------------------------------------------------------------------------------------------------

The list below presents a summary of the used notations:
\\

\begin{table}[ht!]
\renewcommand{\arraystretch}{1.1}
{\small
\begin{tabular}{l l}
$X$ & Child variable\\
$k$& Range of possible values of a multinomial variable $X$\\
$j$ & Index over $X$ values, i.e., $1 \geq j \geq k$ \\
$Y$ & One parent variable\\
$\mathbf{Y}$ & Set of parent variables\\
$n$& Number of parent variables \\
$i$ & Index over parent variables, i.e., $1 \geq i \geq n$ \\
$r_i$& Range of possible values of a multinomial variable $Y_i$\\
$q $ & Total number of configurations of a multinomial parent set $\mathbf{Y}$\\
$l$ & Index over the possible parental configuration values, i.e., $1 \geq l \geq q$ \\
$\mathbf{y}^l$ & The $l^{th}$ configuration of a multinomial parent set $\mathbf{Y}$\\
$\theta_{jl}$ & Equal to $\ln p_{x^j\mid \mathbf{y}^l}$, denoting the log-conditional probability of $X$ in its state $j$ \\
                    & given the $l^{th}$ parent configuration\\
$\theta_{Xl}$ & Equal to $\ln p_{ X \mid \mathbf{y}^l}$, denoting the log-conditional probability of a base distribution variable $X$ \\
                    & given the $l^{th}$ parent configuration\\
$p$ & Probability distribution\\
$m$ & Expected sufficient statistics \\
$s$ & Sufficient statistics \\
\end{tabular}}
\end{table}

\end{document}


