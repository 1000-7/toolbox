% !TEX root = D41-report.tex


\section{Learning Bayesian networks} \label{sec:learningAsInference}

%\comment{Say that we recommend the use of a fully Bayesian approach. Approximate inference techniques (VB / EP, importance sampling, etc) can be optimized for the model class. Maximum likelihood based approaches do not go well hand in hand with approximate inference techniques...}

Consider again the factorization of the full joint distribution $p(\bx)$ in \equref{factorisation}. With this factorization we can efficiently represent the joint probability distribution $p(\bx)$, but it requires that $\pa{X_i}$, i.e., the \textit{parent set} of  $X_i$, is known for each $i=1\ld n$. 
The parents of $X_i$ are exactly the nodes which have an outgoing edge pointing to $X_i$ (e.g., $\pa{X_4}=\{X_2,X_3\}$ for the model in \figref{sampleBN}). 
Algorithms for learning the parent sets, also denoted \textit{structural learning} algorithms, follow one of two approaches: $i)$ search and score  methods, see e.g. \cite{CooperHerskovitz92} and $ii)$ constraint-based techniques \cite{SGS}. Both will be considered in Task 4.1 of the project, and the progress towards the implementation of structural learning in AMIDST is summarized in \secref{parallel}.

As soon as the parent sets in  \equref{factorisation} are determined, the specific conditional distributions $p(X_i\given\pa{X_i})$ can also be learned from data. The approach taken in the AMIDST project is that the conditional distribution $p(X_i\given\pa{X_i})$ is assumed to belong to a specific distributional family  (Gaussian, multinomial, or other member of the exponential family), and learning amounts to finding the optimal \textit{parameterization} of the given distributions. Parameter learning will be considered in Task 4.2 and Task 4.4.



Let \bmtheta\ denote the combination of all parameters of the model (that is, all parameterizations of the local conditional distribution functions in \equref{factorisation}), and let $\calD=\{\bx_1\ld\bx_N\}$ denote the dataset which we are learning from. $\calD$ is a collection of $N$ independent configurations over the variables of the domain. Note that \calD\ may be \textit{incomplete}, in case some of the observations are missing. Missingness can occur, for instance, if some of the variables are latent, or some data-collecting instrument fails. 

Now, parameter learning in Bayesian networks amounts to estimating $\bmtheta$ using some optimization criterion that depend on \calD. The learning generally comes in two different shapes. The most commonly used approach (at least  traditionally) has \textit{maximum likelihood} learning, which attempts to find the model parameters that maximizes the \textit{likelihood} of the model given the data. 
The likelihood of the parameters given the data set $\calD$, 
%$\mathcal{L}(\bmtheta \given \calD)$,   
is defined as  $\mathcal{L}(\bmtheta \given \calD)= \prod_{j=1}^N p(\bx_j\given\bmtheta)$,
and the maximum likelihood estimator is $\hat{\bmtheta}=\arg\max_{\bmtheta} \mathcal{L}(\bmtheta \given \calD)$. 

Maximum likelihood learning is very efficient in exponential family models when there are no missing observations in \calD, because the parameters of each distribution can be optimized independently. 
However, closed-form solutions are not available when the dataset contains missing values. 

Learning parameters when the dataset has missing values, a key ingredient in the data entertained by the AMIDST toolbox, one typically relies on the  Expectation Maximization (EM) algorithm or generalizations thereof. Implementations of the (generalized) EM algorithm typically iterates over the following two steps that are repeated until convergence: $i)$ E-step: Inference in the model given parameter estimates; $ii)$ M-step: Updates of the parameters using inferred states of the variables not observed in the dataset. The EM algorithm is a greedy algorithm that at each iteration guarantees that the likelihood of the present parameter estimates is not lower than the likelihood of the previous estimate as long as the inference algorithm employed by the E-step is exact. Convergence is therefore monitored by keeping track of the likelihood function. If approximate inference is used, no such guarantees exist  OR AM I MISTAKEN? NO,  apparently they optimize a different function (not likelihood) \url{http://papers.nips.cc/paper/2404-approximate-expectation-maximization.pdf}.

Alternatively to (generalizations built on) the maximum likelihood approach we have the \textit{Bayesian}  paradigm. From a simplistic point of view, the main difference is that the Bayesian set-up regards the parameter-vector $\bmtheta$ as random variables, and treat them on an equal footing as all other (unobservable) variables in the domain. Form a modelling perspective this extension is straight forward. The model in \figref{bayesLearn}  extends the model in \figref{sampleBN} by explicitly representing $\bmtheta=\{\theta_i\}_{i=1}^5$, where $\theta_i$ is the parameterization of the conditional distribution function $p(X_i\given\pa{X_i})$. Learning now amounts to calculating the probability distribution $p(\bmtheta\given\calD)$. Parameter-learning is thus reduced to inference in an (extended) Bayesian network model, and approximate inference techniques like variational Bayes message passing, exponential propagation or importance sampling can be used directly for learning. 

\begin{figure}[htb]
  \begin{center}
   \scalebox{1}{
    \begin{tikzpicture}
      \simpleModel      
      \node[latent, above = 0.3 of X1] (theta1) {$\theta_1$}; \edge{theta1}{X1};
      \node[latent, above = 0.3 of X2] (theta2) {$\theta_2$}; \edge{theta2}{X2};
      \node[latent, above = 0.3 of X3] (theta3){$\theta_3$}; \edge{theta3}{X3};            
      \node[latent, above = 0.3 of X4] (theta4){$\theta_4$}; \edge{theta4}{X4};      
      \node[latent, above = 0.3 of X5] (theta5) {$\theta_5$}; \edge{theta5}{X5};
            
    \end{tikzpicture}
    }
  \end{center}
  \caption{The Bayesian network from \figref{sampleBN} extended with explicit representation of the (unknown) parameters.}
  \label{fig:bayesLearn}
\end{figure}


In practice, the \textit{a priori} marginal distributions for each $\theta_i$ must be declared before the learning can be performed. These prior distributions enables domain experts to express knowledge about the parameterization of the distributions that is combined with information from the dataset to obtain the posterior information encoded by $p(\bmtheta\given\calD)$. The prior information consists of the definition of a distributional family for each $\theta_i$ together with a parameterization (the \textit{hyper-parameters}). In AMIDST we will ensure efficient calculation of posteriors by enforcing the distributional families be the conjugate distribution of the likelihood-terms, leaving the hyper-parameters to be chosen freely to incorporate the a priori knowledge. 






\begin{figure}[htb]
  \begin{center}
   \scalebox{1}{
    \begin{tikzpicture}
      \node[obs] (y) {$Y_j$};
      \node[latent, above left = 1 of y] (mu) {$\mu$};
      \node[latent, above right= 1 of y] (tau) {$\tau$};  
        \node[const, above left=0.7 of mu] (mx) {$\mu_0$} ; %
       \node[const, above right=0.7 of mu]  (ax) {$\tau_0$} ; %
       \node[const, above left=0.7 of tau] (atau) {$\alpha$} ; %
       \node[const, above right =0.7 of tau]  (btau) {$\beta$} ; %
	\edge{mx,ax}{mu}
	\edge{atau,btau}{tau}	
	\edge{mu,tau}{y}
	
	\plate {obs} {(y)} {\scalebox{.7}{$j=1\ld N$}} ;

	
    \end{tikzpicture}
    }
  \end{center}
  \caption{A detailed Bayesian network for the variable $Y$, which is assumed to follow a Gaussian distribution with mean $\mu$ and precision $\tau$. $Y$ is observed $N$ times.}
  \label{fig:bayesLearnDetail}
\end{figure}



\figref{bayesLearnDetail}  shows a detailed description of the model for a single variable $Y\sim N\left(\mu,\tau^{-1}\right)$. Prior information about the parameters by assuming $\mu\sim N\left(\mu_0, \tau_0^{-1}\right)$ and $\tau\sim\Gamma(\alpha,\beta)$. The dataset $\calD$ holds  $N$ \textit{i.i.d} observations of $Y$ enabling us to calculate $p(\mu,\tau\given\calD, \mu_0,\tau_0,\alpha,\beta)$. Since the prior distributions are kept inside the conjugate exponential family, the calculation is efficient both in terms of space and time complexity. 

It follows that the learning functionality in AMIDST will rest  heavily on the implementation of the core components in the toolbox (variables, distributions, Bayesian networks, etc.) as well the design to accommodate efficient (approximate) inference using these core components. The implementation of inference engines will constitute a key component for the learning implementation because  efficient and scalable \textit{inference} is both a requirement and a  guarantee for efficient and scalable \textit{parameter learning}. The next section will therefore discuss the top-level design of the AMIDST toolbox, first describing the core components, thereafter moving to the design of the inference and learning components. 






