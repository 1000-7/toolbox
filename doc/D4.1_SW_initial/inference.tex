% !TEX root = D41-report.tex


\section{Learning Bayesian networks} \label{sec:learningAsInference}

%\comment{Say that we recommend the use of a fully Bayesian approach. Approximate inference techniques (VB / EP, importance sampling, etc) can be optimized for the model class. Maximum likelihood based approaches do not go well hand in hand with approximate inference techniques...}

Consider again the factorization of the full joint distribution $p(\bx)$ in \equref{factorisation}. With this factorization we can efficiently represent the joint probability distribution $p(\bx)$, but it requires that $\pa{X_i}$, i.e., the \textit{parent set} of  $X_i$, is known for each $i=1\ld n$. 
The parents of $X_i$ are exactly the nodes which have an outgoing edge pointing to $X_i$ (e.g., $\pa{X_4}=\{X_2,X_3\}$ for the model in \figref{sampleBN}). 
Algorithms for learning the parent sets, also known as \textit{structural learning} algorithms, follow one of two approaches: $i)$ search and score  methods, see e.g. \cite{CooperHerskovits92} and $ii)$ constraint-based techniques \cite{Spi00}. Both will be considered in Task 4.1 of the project, and the progress towards the implementation of structural learning in AMIDST is summarized in \secref{parallel}.

As soon as the parent sets in  \equref{factorisation} are determined, the specific conditional distributions $p(X_i\given\pa{X_i})$ can also be learned from data. The approach taken in the AMIDST project is that the conditional distribution $p(X_i\given\pa{X_i})$ is assumed to be a member of the exponential family  (including, among others, the Gaussian and multinomial distributions).
Therefore, parameter learning amounts to finding the optimal \textit{parameterization} of the given distributions. This task will be considered in Task 4.2 and Task 4.4.

Let \bmtheta\ denote the combination of all parameters of the model (that is, all parameterizations of the local conditional distribution functions in \equref{factorisation}), and let $\calD=\{\bx_1\ld\bx_N\}$ denote the dataset which we are learning from. $\calD$ is a collection of $N$ independent configurations over the variables of the domain. Note that \calD\ may be \textit{incomplete}, in case some of the observations are missing. Missingness can occur, for instance, if some of the variables are latent, or some data-collecting instrument fails. 

Now, parameter learning in Bayesian networks amounts to estimating $\bmtheta$ using some optimization criterion that depend on \calD. The learning generally comes in two different shapes. The most commonly used approach (at least  traditionally) is \textit{maximum likelihood} learning, which attempts to find the model parameters that maximizes the \textit{likelihood} of the model given the data. 
The likelihood of the parameters given the data set $\calD$, 
%$\mathcal{L}(\bmtheta \given \calD)$,   
is defined as  $\mathcal{L}(\bmtheta \given \calD)= \prod_{j=1}^N p(\bx_j\given\bmtheta)$,
and the maximum likelihood estimator is $\hat{\bmtheta}=\arg\max_{\bmtheta} \mathcal{L}(\bmtheta \given \calD)$. 

Maximum likelihood learning is very efficient in exponential family models when there are no missing observations in \calD, because the parameters of each distribution can be optimized independently. 
However, closed-form solutions are not available when the dataset contains missing values. 

Missing values is, though, a key ingredient in the data sets entertained in the AMIDST project. In these cases, maximum likelihood learning typically relies on the  Expectation Maximization (EM) algorithm or generalizations thereof. 
Implementations of the (generalized) EM algorithm iterates over the following two steps that are repeated until convergence: 
$i)$ E-step: Inference in the model given the data-set (using a model with the current parameterization); 
$ii)$ M-step: Updates of the parameters using the posterior distributions calculated in the E-step. 
The EM algorithm is a greedy algorithm, that ensures that the likelihood of the current parameter estimates is non decreasing from one iteration to the next, and therefore also converges to a (local) maximum of the likelihood function. 
Unfortunately, this is only guaranteed when an exact E-step is conducted, and if one uses approximative inference the algorithm may not improve as it moves along. 
Exact inference in the E-step is computational prohibitive in a streaming context; additionally, the M-step can also be computationally challenging. 
Maximum likelihood learning is therefore not implemented in the open-source software of the AMIDST project, but can be employed utilizing the interface that the toolbox offers to the implementation inside the Hugin system.

Alternatively to the maximum likelihood approach we have the \textit{Bayesian}  paradigm. From a simplistic point of view, the main difference between the two is that the Bayesian set-up regards  $\bmtheta$ as a vector of \textit{random variables}, and treats them on an equal footing as all other (unobservable) variables in the domain. 
From a modelling perspective this extension is straight forward: The model in \figref{bayesLearn}  extends the model in \figref{sampleBN} by explicitly representing $\bmtheta=\{\theta_i\}_{i=1}^5$, where $\theta_i$ is the parameterization of the conditional distribution function $p(X_i\given\pa{X_i})$. 
Parameter learning now amounts to calculating the probability distribution $p(\bmtheta\given\calD)$, that is, it is  reduced to inference in an (extended) Bayesian network model. Thereby, approximate inference techniques like variational Bayes message passing, exponential propagation or importance sampling can be used directly for learning. 

\begin{figure}[htb]
  \begin{center}
   \scalebox{1}{
    \begin{tikzpicture}
      \simpleModel      
      \node[latent, above = 0.3 of X1] (theta1) {$\theta_1$}; \edge{theta1}{X1};
      \node[latent, above = 0.3 of X2] (theta2) {$\theta_2$}; \edge{theta2}{X2};
      \node[latent, above = 0.3 of X3] (theta3){$\theta_3$}; \edge{theta3}{X3};            
      \node[latent, above = 0.3 of X4] (theta4){$\theta_4$}; \edge{theta4}{X4};      
      \node[latent, above = 0.3 of X5] (theta5) {$\theta_5$}; \edge{theta5}{X5};
    \end{tikzpicture}
    }
  \end{center}
  \caption{The Bayesian network from \figref{sampleBN} extended with explicit representation of the (unknown) parameters.}
  \label{fig:bayesLearn}
\end{figure}


In practice, the \textit{a priori} marginal distributions for each $\theta_i$ must be declared before the learning can be performed. These prior distributions enables domain experts to express knowledge about the parameterization of the distributions that is combined with information from the dataset to obtain the posterior information captured by $p(\bmtheta\given\calD)$. 
The prior information consists of the definition of a distributional family for each $\theta_i$ together with a parameterization (the so-called \textit{hyper-parameters}). In AMIDST we will ensure efficient calculation of posteriors by enforcing the distributional families be the conjugate distribution of the likelihood-terms.
The hyper-parameters are chosen freely, and this is the vehicle provided to encode prior (expert) knowledge. 






\begin{figure}[htb]
  \begin{center}
   \scalebox{1}{
    \begin{tikzpicture}
      \node[obs] (y1) {$Y_1$};
      \node[obs, right=1.5 of y1] (y2) {$Y_2$};
      \node[latent, above = 1 of y1] (mu) {$\mu$};
      \node[latent, above = 1 of y2] (tau) {$\tau$};  
        \node[const, above left=0.7 of mu] (mx) {$\mu_0$} ; %
       \node[const, above right=0.7 of mu]  (ax) {$\tau_0$} ; %
       \node[const, above left=0.7 of tau] (atau) {$\alpha$} ; %
       \node[const, above right =0.7 of tau]  (btau) {$\beta$} ; %
	\edge{mx,ax}{mu}
	\edge{atau,btau}{tau}	
	\edge{mu,tau}{y1}
		\edge{mu,tau}{y2}
    \end{tikzpicture}
    }
  \end{center}
  \caption{A detailed Bayesian network for the streaming variable $Y_t$ (observed at time $t=1$ and $t=2$). $Y_t$ is assumed to follow a Gaussian distribution with mean $\mu$ and precision $\tau$.}
  \label{fig:bayesLearnDetail}
\end{figure}



\figref{bayesLearnDetail}  shows a detailed description of the model for a streaming variable $Y_t\sim N\left(\mu,\tau^{-1}\right)$ observed  at $t=1$ and  $t=2$. 
Prior information about these parameters are encoded by assuming $\mu\sim N\left(\mu_0, \tau_0^{-1}\right)$ and $\tau\sim\Gamma(\alpha,\beta)$ for given values of the hyper-parameters $\{\mu_0,\tau_0,\alpha,\beta\}$.
The dataset $\calD=\{y_1,y_2\}$ enables us to calculate 
$$
p(\mu,\tau\given y_1,y_2, \mu_0,\tau_0,\alpha,\beta) = \frac{p(y_1\given \mu,\tau)p(y_2\given \mu,\tau)p(\mu\given \mu_0,\tau_0)p(\tau\given\alpha,\beta)}{p(y_1,y_2\given  \mu_0,\tau_0,\alpha,\beta)}.
$$
The calculation is efficient both in terms of both space and time because the model is from the conjugate exponential family. 

It follows that the learning functionality in AMIDST will rest  heavily on the implementation of the core components in the toolbox (variables, distributions, Bayesian networks, and so on) as well the design to accommodate efficient inference using these core components. The implementation of inference engines will constitute a key component for the learning implementation because  efficient and scalable \textit{inference} is both a requirement and a  guarantee for efficient and scalable \textit{parameter learning}. The next section will therefore discuss the top-level design of the AMIDST toolbox, first describing the core components, thereafter moving to the design of the inference components. 






