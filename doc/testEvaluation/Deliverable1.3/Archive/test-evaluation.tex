% !TEX root = deliverable1.3.tex
\section{Test and evaluation methodology}
\label{sec:methodology}

As discussed in the introduction, finding appropriate performance measures on streaming data is more difficult than finding performance measures on non streaming data.  We will therefore start by discussing some relevant performance measures for classification of i.i.d. non streaming data. 

\subsection{Performance measures for classification on i.i.d. data}
\label{sec:static}

Consider a dataset of fixed size $n$, where each instance is independently drawn from a joint probability distribution $P(\bmX,Y)$,. Here  $\bmX$ and $Y$ are random variables; $\bmX$ is known as the explanatory variable and $Y$ is the class label.  These two variables have output spaces $\Omega_X$ and $\Omega_Y$, respectively.
In classification, we typically consider a hypothesis function $h: \, \Omega_X \rightarrow \Omega_Y$, where $\Omega_Y$ is a finite set of class labels; note that $\Omega_Y=\{0,1\}$  for a binary classification problem.
 $\Omega_X$ is a space of all possible explanatory vectors.  
In terms of evaluating the performance of $h$, we use a dataset of input-output pairs $(\bmx_i, y_i)$ that are independently drawn from $\Omega_X  \times \Omega_Y$. 
The result of such an experiment can be shown in a confusion matrix.  An example of a confusion matrix is shown \tabref{catdograbbit}, where the classifier is attempting to distinguish cats, dogs and rabbits. 

\vspace{1ex}
\begin{table}[ht]
\centering
\begin{tabular}{ll|r|r|r|}
\cline{3-5}
&&  \multicolumn{3}{c|}{Predicted class}\\
\cline{3-5}
&& Cat & Dog & Rabbit\\ 
\cline{1-5}
\multicolumn{1}{ |c| }{\multirow{3}{*}{Actual class} }
 & Cat & 5 & 3& 0\\
\cline{2-5}
\multicolumn{1}{ |c| }{} & Dog & 2 & 3 & 1\\
\cline{2-5}
\multicolumn{1}{ |c| }{} & Rabbit & 0 & 2 & 11\\
\cline{1-5}
\end{tabular}
\caption{Example of a confusion matrix.  A classifier is labelling instances as either cats, dogs or rabbits.  The accuracy is the sum of the diagonal elements divided by the total number (in this case 19/27).}
\label{tab:catdograbbit}
\end{table}
\vspace{1ex}

A global measure of the classification algorithm is the classification accuracy which is calculated as the sum of the diagonal elements divided by the sum of all numbers in the table (in this case 19/27).  
It is important to note that the accuracy is not telling the whole story of the classification rule.  
For instance, by looking at the table it is seen that the algorithm distinguishes cats from rabbits quite easily, but it is much harder to distinguish cats from dogs.  This property cannot be realized by looking at the accuracy alone.  

Moreover, accuracy is also very dependent on how evenly the classes are distributed.   For instance, when there are a lot more instances of one class compared to the others, a naive classification rule that always predict the majority class will get a high accuracy, even though the method is not using any of the information that is contained in the explanatory variables.  
These are reasons for inspecting the full confusion matrix for interpreting the classification rule.  

In order to inspect various properties of a classification rule, various performance measures can be calculated from the confusion matrix.  We have decided to limit this exposition to binary classification, while being aware that most of the performance measures can be expanded to discuss multi class classifiers.

For a binary classifier, such as classifying cats and non-cats, the confusion matrix is of size two - by - two; an example is shown in \tabref{binary}.  
It is common to introduce positives and negatives  instead of the class labels.  
A true positive is therefore an actual cat that has been predicted to be a cat, while false positives, true negative and false negatives are defined in an equivalent manner.  


\vspace{1ex}
\begin{table}[ht]
\centering
\begin{tabular}{ll|r|r|}
\cline{3-4}
&&  \multicolumn{2}{c|}{Predicted class}\\
\cline{3-4}
&& Cat & Not cat\\ 
\cline{1-4}
\multicolumn{1}{ |c| }{\multirow{3}{*}{Actual class} }
& Cat & 5 & 3\\
\cline{2-4}
\multicolumn{1}{ |c| }{} & Not cat & 2 & 17 \\
\cline{1-4}
\end{tabular}
\caption{Example of a confusion matrix for a classifier of cats and not cats. The accuracy is 22/27.}
\label{tab:binary}
\end{table}
\vspace{1ex}

\vspace{1ex}
\begin{table}[ht]
\centering
\begin{tabular}{ll|r|r|}
\cline{3-4}
&&  \multicolumn{2}{c|}{Actual Condition}\\
\cline{3-4}
&& Positive & Negative\\ 
\cline{1-4}
\multicolumn{1}{ |c| }{\multirow{3}{*}{Test outcome} }
& Positive & 5 & 2\\
\cline{2-4}
\multicolumn{1}{ |c| }{} & Negative & 3 & 17 \\
\cline{1-4}
\end{tabular}
\caption{Example of a confusion table for a classifier of cats and not cats. The true positives and true negatives are on the diagonal, while the two other numbers are the false positives and the false negatives.}
\label{tab:confusionTable}
\end{table}
\vspace{1ex}

The results are commonly shown in a confusion table (see \tabref{confusionTable}), which is not the same as a confusion matrix.  From a confusion table it is easy to calculate numerous numbers that describes the classification rule.  Specifically, we mention the true positive and false positive rates.  True positive rates, also known as recall, is the number of true positives divided by the total number actual positives.  The false positive rates, also known as fall-out, is the number of false positives divided by the total number actual positives. 
By investigating various numbers that can be deduced from the confusion table, it is possible to discuss classification rules, even when the datasets are unevenly distributed.  That is, when some class label have more instances than others.

However, these numbers do not take into account that some misclassifications might be more costly than others.  For instance, a false positive might be more costly than a false negative.  For instance in the case of diagnosing cancer, it might be more costly to not treat a person that is sick, compared to treating a healthy person.  Moreover, the cost of each false positive (or false negative) may not be constant either.  For instance, if the classifier is predicting whether a client in a bank will default a loan or not, the cost is clearly related to the size of the loan in question.  The next subsection includes a procedure to include such costs in a performance measure.

\subsubsection{Empirical risk}
\label{sec:empRisk}

In mathematical optimization, statistics, decision theory and machine learning, a loss function or a cost function is a function that maps an event or values of one or more variables onto a real number that is intuitively representing some \emph{cost} associated with the event. Loss functions can be used on optimization problems, when an algorithm or a method is optimized by minimizing the loss function.  Moreover, loss functions are frequently used to diagnose and compare various algorithms or methods.  
We define the \emph{loss function} as a real and lower-bounded function $L$ on $\Omega_X \times \Omega_Y \times \Omega_Y$.  The value of the loss function at an arbitrary point $(x, h(\bmx), y)$ is interpreted as the loss, or cost, of taking the decision $h(\bmx)$ at $\bmx$, when the right decision is $y$.  Notice that the loss function is defined to also depend on $\bmx$.  This is of high practical use, because a certain misclassification might be more expensive than another. 

In the frequentist perspective, the expected loss is often referred to as the risk function \cite{Vap00}.  It is obtained by taking the expected value over the loss function with respect to the probability distribution $P(\bmX,Y): \Omega_X\times \Omega_Y \rightarrow \mathbb{R}^+$.  The \emph{risk function} is given by

\begin{equation}
\label{def:risk}
R(h) = \int_{\Omega_X,\Omega_Y} L(x,h(\bmx),y) dP(\bmx,y).
\end{equation}

In the case when the costs are independent of $x$ and also that there is no cost related to correct classification, the risk function reduces to the well known expected cost of misclassification (ECM)

\begin{equation}
\label{eq:ecm}
ECM =  c(1|0)p(1|0)p_0  + c(0|1)p(0|1)p_1.
\end{equation}
Here, $c(1|0)$ is the cost for misclassifying an item of class zero as class one and $p(1|0)$ is the misclassification probability given class zero.  The quantities $c(0|1)$ and $p(0|1)$ are defined equivalently, while $p_0$ and $p_1$ are the priors.  

In general, the risk $R(h)$ cannot be computed because the distribution $P(\bmX,Y)$ is unknown.  However, we can compute an approximation, called empirical risk, by averaging the loss function on the data set $\calD$ of size $N$, where each element in $\calD$ is $(\bmx_i, y_i)$.  The empirical risk is given by 

\begin{equation}
\label{def:empRisk}
R_{emp}(h, \calD) = N^{-1} \sum_{i=1}^N L(x_i, h(\bmx_i), y_i).
\end{equation}
%Notice that $L$ is an array of $N \times 2\times 2$ elements.  
Many supervised learning algorithms are optimized by finding the $h$ in a hypothesis space $\mathcal{H}$ that minimizes the empirical risk on a data set that is used only for training the classification rule.  In this case, a separate data set is needed for testing the classifier.  In this document, we focus only on testing classifiers.  We only use empirical risk to quantitatively describe the methods.

\subsubsection{Evaluation of families of classification rules}
\label{sec:hypothesisSpace}

So far we have discussed how to evaluate a single classification rule.  
However, probabilistic classifiers operate by calculating the probability distribution $P(Y\given\bmx)$, and then comparing this probability to a certain threshold.  
We will call this estimated probability the output function $q: \Omega_X \rightarrow \mathbb{R}^+$.  In the probabilistic framework the range of $q$ is $[0, 1]$, but this restriction is not necessary for this theory to be well-defined.  
The potential classification rules are the family of hypothesis functions $\mathcal{H}$, where each element $h_T:\Omega_X \rightarrow \Omega_Y$ has the form 

\begin{equation}
\label{eq:ht}
h_T(\bmx) = 
\begin{cases}
0 \quad \mbox{if} \quad q(\bmx) \leq T\\
1 \quad \mbox{otherwise.}
\end{cases}
\end{equation}

It is of interest to evaluate all these classification rules.  The receiver operating characteristic (ROC) is a plot of the true positive rate as a function of the false positive rate, as the threshold $T$ varies over all relevant values.  An example is seen in figure \ref{fig:ROC}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.70]{figures/ROC.png}
\caption{\label{fig:ROC} Receiver operating characteristics curve.  True positive or hit rate is shown as a function of false positive or false alarms rate.  The dashed line shows the ROC curve of the random guess.}
\end{figure}


The ROC curve allows a visual exposition of the family of classifiers $\mathcal{H}$, in the sense of true positive rates and false positive rates.  In particular, it is easy to see which threshold is needed for a certain hit rate or true positive rate.  This plot is clearly independent on class distributions and the whole cost content.

Moreover, it is also of interest to reduce all this information into a single number.  The area under the ROC curve, also known as AUC, is such a number.  
AUC is independent of $T$. The AUC is a popular method for evaluating classification problems where class imbalance is vital, because it is invariant to the class distribution. 
AUC has the statistical interpretation that it is the probability that a random member of the ``positive'' class is scored higher than a random member of the ``negative'' class.  
AUC is therefore a measure of the \emph{ranking ability} of the output function.  
This is particularly relevant if one wants to change the classification threshold as a consequence of changing class distributions or  changing misclassification costs \cite{Wu07}.  
Moreover, it has also been pointed out that AUC is more preferable than accuracy for model evaluation \cite{Gam10}.  



%It may be difficult to comprehend what AUC is at this point, but we will return to it afterward.

We will now discuss the underlying statistical properties of AUC. First, let $\bmX_0$ and $\bmX_1$ be random variables with probability distributions $P(\bmX | Y = 0)$ and $P(\bmX | Y = 1)$, respectively.  We define the random variables $Q_0 = q(\bmX_0)$ and $Q_1 = q(\bmX_1)$.  To summarize, $Q_0$ is basically the output value you get when you pick a random sample of class zero and calculate the probability for it to be a member of class one; similarly for $Q_1$.  

The probability $P(Q_1 > Q_0)$ is of interest, because this says what is the probability that if you take one sample by random from each of the populations, what is the chance that the output value from sample one is higher than the output value of sample zero.  This question is independent of $T$, meaning that the discussion about priors and costs are not needed. This probability is called the concordance probability.

Without exposing the details, it is possible to show that
\begin{equation}
\label{eq:concurrent}
\mbox{AUC} = P(Q_1 > Q_0).
\end{equation}
It is important to note that nothing need to be assumed about the probability distributions of $Q_0$ and $Q_1$.  Furthermore, it is worth noting that the concordance probability is exactly equal the common language effect size of the Mann-Whitney $U$ test.  We discuss the Mann-Whitney $U$ test next.

\subsubsection{Mann-Whitney $U$ test}
\label{sec:U}

The Mann-Whitney $U$ test  \cite{Man47} is a nonparametric test of the null hypothesis that two populations are the same against an alternative hypothesis where one population tends to have larger values than the other.  It is the nonparametric version of common $t$-test, where both populations are assumed to be of normal distributions.  It is nearly as efficient as the $t$-test on normal data and far more efficient on non normal data.  In our context, we can use the Mann-Whitney $U$ test to discuss whether values of $Q_1$ are consistently larger than values of $Q_0$.  

A relevant assumption for our problem is that all samples of $Q_0$ and $Q_1$ are assumed to be independent of each other.  On stationary streams, we know this is not true as two consecutive measurements are clearly dependent.  However, in the context of interpretation, we can imagine that the samples of randomized.  

A more important assumption is that under the null hypothesis, the probability distributions of $Q_0$ and $Q_1$ are exactly equal, while the alternative hypothesis is that the distributions have different means, but similar shapes.  It is clearly a problem if for instance $Q_0$ is one sided exponentially distributed, while $Q_1$ is normally distributed with a larger mean.   
Other assumptions can be stated for this test as well.  A more thorough discussion can be found in \cite{Fay10}.

We define a data set $\calD$ with $n$ input-output pairs $(x_i, y_i)$, independently drawn from $P(\bmX,Y)$.  From the data set we have two populations $\bmq_0 = \{q(\bmx_i) , | \, y_i = 0 \}$ and $\bmq_1 = \{q(\bmx_i) , | \, y_i = 1 \}$.  Their sizes are $n_0$ and $n_1$ so that $n_0 + n_1 = n$.  Calculating the $U$ statistics is straightforward, where these two values are obtained 

\begin{equation}
\label{eq:U}
U_0 = \sum_{i=1}^{n_0}\sum_{j=1}^{n_1} H(\,q_{1,j} - q_{0,i}    \,) \quad \mbox{and} \quad 
U_1 = \sum_{i=1}^{n_0}\sum_{j=1}^{n_1} H( \,q_{0,i} - q_{1,j}    \,).
\end{equation}
Here, $H(\cdot)$ is the heaviside step function and notice that $U_0 + U_1 = n_0n_1$.  For large samples, each $U$ ($U_0$ or $U_1$) is approximately normally distributed. In that case, the standardized value

\begin{equation}
\label{eq:z}
z = \frac{U_0 - m_{U}}{\sigma_{U}},
\end{equation}
where $m_U$ and $\sigma_U$ are the mean and standard deviation of $U$ given by

\begin{equation}
\label{eq:z}
m_U = \frac{n_0n_1}{2} \quad \mbox{and} \quad 
\sigma_U = \sqrt{\frac{n_0n_1(n_0 + n_1 + 1)}{12} }.
\end{equation}

Significance of test can be checked in tables of the normal distribution.  Although, such an hypothesis test is interesting by itself, we are more interested in the concordance probability $P(Q_1 > Q_0)$ which is defined by

\begin{equation} 
\label{eq:concordance}
P(Q_1 > Q_0) = \frac{U_1}{n_0n_1}.
\end{equation}

It is important to note that even though the Mann-Whitney $U$ test is dependent on whether the shapes of the probability distributions of $Q_0$ and $Q_1$ are similar, this requirement is not necessary for the concordance probability.  To be more explicit, the problem when $Q_0$ is for instance one sided exponentially distributed and $Q_1$ is normally distributed, is not a violation of preliminary assumptions.  

The concordance probability or AUC are therefore a measure of the ranking ability of the output function.  The Mann Whitney $U$-test allows one to test whether the result that is obtained is not just be chance in the way the data set is drawn.  It can also be used for designing experiments in terms of reasoning about how large data sets are needed for making an effective test.

Moreover, equation \eqref{eq:concordance} shows a simple way of calculating $P(Q_1 > Q_0)$ and AUC.

\todo{multi class AUC.}

\subsection{Performance measures for classification on streaming data}
\label{sec:stream}

This section includes various evaluation methods for classification on data streams.  Central to choices of evaluation methods are stationarity versus concept-drift, class imbalance, whether a scoring function exists, computational constraints and also the importance of early detection when a data stream changes behaviour.

\subsubsection{Stationary data streams}
\label{sec:stationary}

Let $\{X_{t}\}$ be a stochastic process, where $p_X(\bmx_{t_1 + \tau},...,\bmx_{t_k + \tau} )$ is the probability distribution function of the joint distribution at $t_1 + \tau,...,t_k + \tau$.  Then $\{X_t\}$ is a stationary process, or a stationary stream, if, for all $k$, for all $\tau$ and for all $t_1 + \tau,...,t_k + \tau$, 

\begin{equation}
\label{eq:stationarity}
p_X(\bmx_{t_1 + \tau},...,\bmx_{t_k + \tau} ) = p_X(\bmx_{t_1},...,\bmx_{t_k} ),
\end{equation}
where the $\bm{x_t}$s are vectors of fixed size.  Clearly, $p_X(\cdot)$ is not a function of time.  

In stationary streams, the mean and the variance, if they exist, do not vary.  The covariance structures to neighboring instances are also preserved.  To summarize, stationary streams are more general than i.i.d. streams, where the covariance to all other instances are zero.  

In \cite{Gam13}, the prequential empirical risk is defined as 

\begin{equation}
\label{eq:prequentialRisk}
R_{emp}(h, \{X_{t_k}\}) = k^{-1} \sum_{i=1}^k L(\bmx_{t_i} , h(\bmx_{t_i} ), y_{t_i}),
\end{equation}
where $y_{t_i}$ is the class label at time $t_i$ and $n$ is the number of samples up to $t_k$.  In the original paper, the notation is different and the measure is called the prequental error  Adaptations are made to comply with notation and definitions in section \ref{sec:static}.  Notice, that the loss function in the prequential empirical risk, is generalized compared to \cite{Gam13}, to also include dependency of $\bm{x_{t_i}}$, which may in fact be just $t_i$.  This generalization means that it is possible to model evolving loss as well.

\drop{\todo{Sigve says: Include a discussion of statistical interpretation of loss functions on stationary data.  Dependence between timesteps is essential. Is this a problem? What opportunities do we have with evolving loss? Maybe nothing, but worth reflecting on.}}

AUC is also popular in a streaming context, in the case when the classification is based on a scoring function, which is common for Bayesian networks. 
Specialized learning algorithms for imbalanced streams are proposed in \cite{Dit13, Hoe12, Lic10}, where it is also pointed out that this problem is particularly difficult and effective algorithms for evaluation is vital.  
AUC is calculated on limited holdout sets are used in  \cite{Dit13, Lic10}, while AUC is calculated on the entire stream in  \cite{Hoe12}. If the whole stream is used, it may have computational problems related to memory and cpu time.  

The prequential AUC at time step $t_k$ can be calculated by
\begin{equation}
\label{eq:prequentialAUC}
\mbox{AUC}_{t_k}= \frac{U_{1,k}}{n_{0,k}n_{1,k}},
\end{equation}
where $n_{0,k}$ and $n_{1,k}$ are the number of negatives and positives up to $t_k$.  To be precise, $n_{0,k} + n_{1,k} = k$.  The quantity $U_{1,k}$ is calculated by the second $U$-statistic as of equation \eqref{eq:U} (using $n_{0,k}$ and $n_{1,k}$).

On a data stream there is an opportunity of calculating AUC recursively with the following algorithm.

\begin{equation}
\label{eq:prequentialAUC2}
U_{1,k}= 
\begin{cases}
U_{1,k-1} + \sum_{j=1}^{n_{1,k}} H( \,q_{0,n_{0,k}} - q_{1,j}    \,)
 \quad &\mbox{for} \quad y_{t_k} = 0\\
U_{1,k-1} + \sum_{i=1}^{n_{0,k}} H( \,q_{0,i} - q_{1,n_{1,k}}    \,)
\quad &\mbox{for} \quad y_{t_k} = 1.\\
\end{cases}
\end{equation}
Clearly AUC calculation is $O(k)$, which might be a problem for very long streams.  

Another method for calculating AUC  involves sorting the scores of all instances and iteration over this list. It is essential that the sorted list always keeps the mapping from each score to either a positive or a negative.  At each time step, the list of scores, the number of positives and the number of negatives are updated.  The AUC is calculated by algorithm \ref{AUCalg}.  This method is also $O(k)$.

\begin{algorithm}[H]
 \KwData{$s$: Current score, $sortedList$: sorted list of all scores in a stream, $p$: number of positives in sorted list, $n$: number of negatives in sorted list}
 \KwResult{Prequential $AUC$ at the current time step}
$sortedList.update(s)$;\\
$p.update(s)$;\\
$n.update(s)$;\\
$c \leftarrow 0, AUC \leftarrow 0$;\\
\ForAll{scores $t \in$ sortedList}{
\If{isPositive($t$)}{
$c \leftarrow c + 1$
}\Else{
$AUC = AUC + c$;
}
}
$ AUC = AUC/(p \cdot n)$;
\label{AUCalg}
 \caption{Calculation of prequential AUC at each time step in a stream.  Here, $sortedList.update(s)$ takes in the current score $s$ and places it correctly in the sorted list. The method $isPositive(s)$ computes whether the score $s$ is positive or not, while $p.update(s)$ and $n.update(s)$ updates the number of positives $p$ and negatives $n$.}
\end{algorithm}

It is worth noting a few points about the statistical interpretability of AUC on stationary streams.  Unless the stream is also i.i.d. the $q_{0,i}$s and the $q_{1,i}$s are generally dependent on neighboring points.  This fact is however not contradicting the fact that AUC is equal to the concordance probability $ P(Q_1 > Q_0)$.  This is because the definitions of $Q_0$ and $Q_1$ are $Q_0 = q(X_0)$ and $Q_1 = q(X_1)$ and 
that $X_0$ and $X_1$ are random variables with probability distributions $P(X | Y = 0)$ and $P(X | Y = 1)$.  The key point is that $P(X | Y = 0)$ and $P(X | Y = 1)$ are not dependent on time in stationary streams.  This is not true on non stationary streams.  

\drop{In practice, samples of $Q_0$ and $Q_1$ can be though of as picking samples from $\bv{q_0}$ and $\bv{q_1}$, respectively.}

\subsubsection{Data streams that involve concept-drift}

Concept drift is generally understood as unforeseen changes in statistical properties of the target variable.  In the case of regression this can basically be understood as non stationary of the dependent variable.  In the case of classification, it is understood as the class distribution is \emph{not} constant in time.  

However, this definition is not always clear cut in the literature.  For instance in \cite{Brz14}, concept drift is understood broader, where non stationarity of explanatory variables are present in addition to time dependent class distributions.   For clarity, in this paper we refer to concept drift in the sense of \cite{Brz14}.

In \cite{Gam13}, two estimators are suggested for dealing with concept drift and/or non stationary explanatory variables.  The first estimator involves calculating the prequential empirical risk over a sliding window of $w$ samples. 

\begin{equation}
\label{eq:prequentialRisk2}
R_{emp}(t_k, \{h_{t_k}\}, \{X_{t_k}\}, w) = w^{-1} \sum_{i=k - w +1}^k L(\bmx_{t_i} , h_{t_i}(\bmx_{t_i} ), y_{t_i}).
\end{equation}
Notice that $R_{emp}(t_k, \{h_{t_k}\}, \{X_{t_k}\}, w)$ is a function of time and not just a single number.  Hence, the measure reflects the expected loss at $t_{k-\mbox{floor}(w/2)}$.  Notice also that the classification rule itself $h_{t_i}$ is allowed to be a function of time.

The second estimator involves fading factors and is defined as follows

\begin{equation}
\label{eq:prequentialRisk3}
R_{emp}(t_k, \{h_{t_k}\}, \{X_{t_k}\}, \alpha) =\frac{\sum_{i=1}^k \alpha^{i-k}L(\bm{x_{t_i}} , h_{t_i}(\bm{x_{t_i}} ), y_{t_i})}{\sum_{i=1}^k \alpha^{i-k}} \quad \mbox{where} \quad 0 \leq \alpha \leq 1.
\end{equation}
When $\alpha$ is equal to one, this reduces to the prequental empirical risk with no forgetting factor, while in the case when $\alpha$ is equal to zero, the estimator forgets all effects before $t_k$.

In the special case when the loss function is zero-one and $h$, or $h_k$, is consistent, then it is shown in \cite{Gam13} that 
$R_{emp}(t_k, \{h_{t_k}\}, \{X_{t_k}\}, \alpha)$, $R_{emp}(t_k, \{h_{t_k}\}, \{X_{t_k}\}, w) $ and $R_{emp}(h, \{X_{t_k}\})$ approximates the Bayes error in the limiting cases.

As said in \ref{sec:stationary}, $P(X | Y = 0)$ and $P(X | Y = 1)$ are not dependent on time in stationary streams. However, in our definition of concept-drift, which includes non stationary explanatory variables, $P(X | Y = 0)$ and $P(X | Y = 1)$ are generally dependent on time.  This means that an AUC that is calculated by either equation \eqref{eq:prequentialAUC2} or algorithm \ref{AUCalg} at the current time step, may be severely biased by very old measurements.

To overcome this problem, it is suggested in \cite{Brz14}, a prequantial AUC with a forgetting factor.  The method involves calculating AUC on a sliding window of fixed size in a similar manner as algorithm \ref{AUCalg}.  This algorithm is explained in algorithm \ref{AUCalg2}.

\begin{algorithm}[H]
 \KwData{$s$: Current score, $sortedList$: sorted list of scores in the sliding window, $p$: number of positives in sorted list, $n$: number of negatives in sorted list}
 \KwResult{Prequential $AUC$ at the current time step}
$sortedList.update(s)$;\\
$p.update(s)$;\\
$n.update(s)$;\\
$c \leftarrow 0, AUC \leftarrow 0$;\\
\ForAll{scores $t \in$ sortedList}{
\If{isPositive($t$)}{
$c \leftarrow c + 1$
}\Else{
$AUC = AUC + c$;
}
}
$ AUC = AUC/(p \cdot n)$;
\label{AUCalg2}
 \caption{Calculation of prequential AUC at each time step in a stream.  Here, $sortedList.update(s)$ takes in the current score $s$ and throws out the oldest score before resorting the list. The method $isPositive(s)$ computes whether the score $s$ is positive or not, while $p.update(s)$ and $n.update(s)$ updates the number of positives $p$ and negatives $n$.}
\end{algorithm}

\drop{\todo{Sigve says: Maybe discuss stationary explanatory variables with consept drift versus non stationary explanatory variables with concept drift.}}

\subsubsection{Risk related to early and late warnings}

When working on data streams it may sometimes be of interest to give as early warnings as possible.  Another way of saying this is to penalize late warnings more and more.  We therefore suggest this measure, where the notation is the same as in equation \eqref{eq:prequentialRisk2}

\begin{equation}
\label{eq:prequentialRisk3}
R_{emp}(t_k, \{h_{t_{k+m}}\}, \{X_{t_k}\}, w) = w^{-1} \sum_{i=k - w +1}^k L(\bmx_{t_i} , h_{t_{i+m}}(\bmx_{t_i} ), y_{t_{i+m}}).
\end{equation}
Here, $m$ denotes some time steps into the future and $h_{t_{k+m}}$ denotes prediction at $t_{k+m}$.
\todo{Sigve says: Reflect more and relate to Cajamar. Helge has promised to help out.}


%
%In the use case scenarios in the AMIDST software, all problems are binary classifiers, which involve dividing the streams into sub streams that are labeled as either positives or negatives.  There are two important approaches here.
%
%The first approach deals with multiple streams and the global time dependence is removed by sampling all these streams into multiple sub streams, which are starting and ending at the same time steps.  Each sub stream is labeled as either a positive or negative based on the data at the end time.  An evaluation time step that is a fixed between the start and the end is also defined.  The explanatory variables are derived from the data between the start and the evaluation time step.  In this sense, the data is basically i.i.d.
%
%The second approach is when there is basically one stream where one can assume stationarity on a global scale.  Sub streams with large enough distance to other sub streams are taken out of the stream.  These sub streams are labeled as either a positive or a negative.  For instance, a positive is when something is happening towards the end of the sub stream, while a negative is a sub stream where nothing happens.  When the AMIDST software run, the output function is evaluated at each time step.  Depending of the problem, a heuristic algorithm is chosen to output a single number for each sub stream based on the output values.  This can for instance be the maximum value of the output function on an interval that is prior to an event.  
%





 

%\emph{Here we should cover general methods for doing test and evaluation of models in a streaming
%  context. These methods will subsequently be instantiated in relation to the three use case providers so I
%  guess that we should primarily consider the methods that are directly related to the needs of the use case
%  providers, but (taking the back ground of one of the reviewers into account) we might probably benefit from
%  going a bit beyond the immediate needs and put all this stuff into a broader context ...}
%
%\cite{Kap14}, \cite{Gam09}, \cite{Gam09_2}, \cite{Gam13}, 
